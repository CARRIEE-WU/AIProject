{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/CARRIEE-WU/AIProject/blob/master/AIproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DqIJj9PEjruS",
        "outputId": "e6b4fd09-1918-4d84-95c1-353008a919d9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'AIProject' already exists and is not an empty directory.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/a945120/AIProject.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import print_function\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "from PIL import Image\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import copy\n",
        "\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "q21J5rEdF47j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "KlWrloqjF66w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def image_loader(image_name, imsize):\n",
        "  loader = transforms.Compose([transforms.Resize(imsize), transforms.ToTensor()])\n",
        "  image = image.open(image_name)\n",
        "\n",
        "  image = loader(image).unsqueeze(0)\n",
        "  return image.to(device, torch.float)"
      ],
      "metadata": {
        "id": "kEFKl6HwF-QQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def imshow(tensor, title=None):\n",
        "  unloader = transforms.ToPILImage()\n",
        "  image = tensor.cpu().clone()\n",
        "  image = image.squeeze(0)\n",
        "  image = unloader(image)\n",
        "  plt.imshow(image)\n",
        "  if title is not None:\n",
        "    plt.title(title)\n",
        "  plt.pause(0.001)"
      ],
      "metadata": {
        "id": "0KIxWnAqGEp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "imsize = 512 if torch.cuda.is_available() else 128\n",
        "image_directory = \"../images/\"\n",
        "style_img = image_loader(image_directory + \"meadow_painting.jpg\", imsize)\n",
        "content_img = image_loader(image_directory + \"love_1.jpg\", imsize)\n",
        "assert style_img.size() == content_img.size(), \"we need to import style and content images of the same size\"\n",
        "plt.ion()"
      ],
      "metadata": {
        "id": "mfnP7g45GBz2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "imshow(style_img, title='Style Image')"
      ],
      "metadata": {
        "id": "8P0gY9fYGkJS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure()\n",
        "imshow(content_img, title='Content Image')"
      ],
      "metadata": {
        "id": "mlQo3s-iGqjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentLoss(nn.Module):\n",
        "  def __init__(self, target):\n",
        "    super(ContentLoss, self).__init__()\n",
        "\n",
        "    self.target = target.detach()\n",
        "\n",
        "  def forward(self, input):\n",
        "    self.loss = F.mse_loss(input, self.target)\n",
        "    return input"
      ],
      "metadata": {
        "id": "zxucxTaDIOBd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def gram_matrix(input):\n",
        "  a,b,c,d = input.size()\n",
        "  features = input.view(a * b, c * d)\n",
        "  G = torch.mm(features, features.t())\n",
        "  return G.div(a * b * c * d)"
      ],
      "metadata": {
        "id": "8qYSm8V3Iy7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class StyleLoss(nn.Module):\n",
        ""
      ],
      "metadata": {
        "id": "pKjsZDRRJPwV"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}